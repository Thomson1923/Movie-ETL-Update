{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "\n",
    "# from config import db_password\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Add the function that takes in three arguments;\n",
    "def extract_transform_load():\n",
    "\n",
    "    # 2. Read in the kaggle metadata and MovieLens ratings CSV files as Pandas DataFrames.\n",
    "    kaggle_metadata = pd.read_csv(f'{file_dir}movies_metadata.csv', low_memory=False)\n",
    "    ratings = pd.read_csv(f'{file_dir}ratings.csv')\n",
    "\n",
    "    # 3. Open the read the Wikipedia data JSON file.\n",
    "    with open(f'{file_dir}/wikipedia-movies.json', mode='r') as file:\n",
    "        wiki_movies_raw = json.load(file)  # Load data from JSON file into a list of dicts\n",
    "    \n",
    "    # 4. Read in the raw wiki movie data as a Pandas DataFrame.\n",
    "    wiki_movies_df=pd.DataFrame(wiki_movies_raw)\n",
    "    # 5. Return the three DataFrames\n",
    "    return wiki_movies_df, kaggle_metadata, ratings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Add the clean movie function that takes in the argument, \"movie\".\n",
    "def clean_movie(movie):\n",
    "    movie = dict(movie) #create a non-destructive copy\n",
    "    alt_titles = {}    # Create empty dict to hold alternate titles, if any\n",
    "    for key in ['Also known as','Arabic','Cantonese','Chinese','French',     # Loop through Keys that may hold alternate titles \n",
    "                'Hangul','Hebrew','Hepburn','Japanese','Literally',\n",
    "                'Mandarin','McCune–Reischauer','Original title','Polish',\n",
    "                'Revised Romanization','Romanized','Russian',\n",
    "                'Simplified','Traditional','Yiddish']:\n",
    "        if key in movie:                                        # If any alternate title Keys have values ... \n",
    "            alt_titles[key] = movie[key]                        #   create a Key : Value entry in the alt_title dict\n",
    "            movie.pop(key)                                      #   delete the original Key : Value entry in the movie dict\n",
    "    if len(alt_titles) > 0:                                     # If any alt_titles are found and stored ...\n",
    "        movie['alt_titles'] = alt_titles                        #   store the \"alt_titles' dict in the original dict\n",
    "\n",
    "    # merge column names\n",
    "    def change_column_name(old_name, new_name):\n",
    "        if old_name in movie:\n",
    "            movie[new_name] = movie.pop(old_name)\n",
    "    \n",
    "    change_column_name('Adaptation by', 'Writer(s)')\n",
    "    change_column_name('Country of origin', 'Country')\n",
    "    change_column_name('Directed by', 'Director')\n",
    "    change_column_name('Distributed by', 'Distributor')\n",
    "    change_column_name('Edited by', 'Editor(s)')\n",
    "    change_column_name('Length', 'Running time')\n",
    "    change_column_name('Original release', 'Release date')\n",
    "    change_column_name('Music by', 'Composer(s)')\n",
    "    change_column_name('Produced by', 'Producer(s)')\n",
    "    change_column_name('Producer', 'Producer(s)')\n",
    "    change_column_name('Productioncompanies ', 'Production company(s)')\n",
    "    change_column_name('Productioncompany ', 'Production company(s)')\n",
    "    change_column_name('Released', 'Release Date')\n",
    "    change_column_name('Release Date', 'Release date')\n",
    "    change_column_name('Screen story by', 'Writer(s)')\n",
    "    change_column_name('Screenplay by', 'Writer(s)')\n",
    "    change_column_name('Story by', 'Writer(s)')\n",
    "    change_column_name('Theme music composer', 'Composer(s)')\n",
    "    change_column_name('Written by', 'Writer(s)')\n",
    "    \n",
    "    return movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7310"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 Add the function that takes in three arguments;\n",
    "# Wikipedia data, Kaggle metadata, and MovieLens rating data (from Kaggle)\n",
    "\n",
    "def extract_transform_load():\n",
    "\n",
    "    kaggle_metadata = pd.read_csv(f'{file_dir}movies_metadata.csv', low_memory=False)\n",
    "    ratings = pd.read_csv(f'{file_dir}ratings.csv')\n",
    "\n",
    "    with open(f'{file_dir}/wikipedia-movies.json', mode='r') as file:\n",
    "        wiki_movies_df = json.load(file)  # Load data from JSON file into a list of dicts\n",
    "\n",
    "        \n",
    "    return wiki_movies_df, kaggle_metadata, ratings\n",
    "    \n",
    "    # 3. Write a list comprehension to filter out TV shows.    \n",
    "    with open(f'{file_dir}/wikipedia-movies.json', mode='r') as file:\n",
    "        wiki_movies_raw = json.load(file)  # Load data from JSON file into a list of dicts\n",
    "\n",
    "    #wiki_movies = [movie for movie in wiki_movies_raw if 'Television series' not in movie]\n",
    "len(wiki_movies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7310"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Write a list comprehension to filter out TV shows.    \n",
    "file_dir = \"C:/Users/Bob Thomson/ETL Module/\"\n",
    "with open(f'{file_dir}/wikipedia-movies.json', mode='r') as file:\n",
    "    wiki_movies_raw = json.load(file)  # Load data from JSON file into a list of dicts\n",
    "\n",
    "wiki_movies_raw = [movie for movie in wiki_movies_raw  # Perform list comprehension to eliminate TV shows\n",
    "                   if 'Television series' not in movie]\n",
    "len(wiki_movies_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Write a list comprehension to iterate through the cleaned wiki movies list\n",
    "# and call the clean_movie function on each movie.\n",
    "movies_Step4 = [clean_movie(movie) for movie in wiki_movies_raw] # Perform list comprehension to use cleaning function\n",
    "# movies_Step4[1:3]  # Review the first two dicts in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Read in the cleaned movies list from Step 4 as a DataFrame.\n",
    "movies_Step5_df=pd.DataFrame(movies_Step4)\n",
    "#columns_Step4=sorted(movies_Step5_df.columns.tolist())  # Create list of column headers\n",
    "#columns_Step4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>year</th>\n",
       "      <th>imdb_link</th>\n",
       "      <th>title</th>\n",
       "      <th>Based on</th>\n",
       "      <th>Starring</th>\n",
       "      <th>Narrated by</th>\n",
       "      <th>Cinematography</th>\n",
       "      <th>Release date</th>\n",
       "      <th>Running time</th>\n",
       "      <th>...</th>\n",
       "      <th>Number of employees</th>\n",
       "      <th>Divisions</th>\n",
       "      <th>Subsidiaries</th>\n",
       "      <th>Predecessor</th>\n",
       "      <th>Founders</th>\n",
       "      <th>Area served</th>\n",
       "      <th>Products</th>\n",
       "      <th>Services</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Operating income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Adventures_o...</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>https://www.imdb.com/title/tt0098987/</td>\n",
       "      <td>The Adventures of Ford Fairlane</td>\n",
       "      <td>[Characters, by Rex Weiner]</td>\n",
       "      <td>[Andrew Dice Clay, Wayne Newton, Priscilla Pre...</td>\n",
       "      <td>Andrew \"Dice\" Clay</td>\n",
       "      <td>Oliver Wood</td>\n",
       "      <td>[July 11, 1990, (, 1990-07-11, )]</td>\n",
       "      <td>102 minutes</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 154 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url    year  \\\n",
       "0  https://en.wikipedia.org/wiki/The_Adventures_o...  1990.0   \n",
       "\n",
       "                               imdb_link                            title  \\\n",
       "0  https://www.imdb.com/title/tt0098987/  The Adventures of Ford Fairlane   \n",
       "\n",
       "                      Based on  \\\n",
       "0  [Characters, by Rex Weiner]   \n",
       "\n",
       "                                            Starring         Narrated by  \\\n",
       "0  [Andrew Dice Clay, Wayne Newton, Priscilla Pre...  Andrew \"Dice\" Clay   \n",
       "\n",
       "  Cinematography                       Release date Running time  ...  \\\n",
       "0    Oliver Wood  [July 11, 1990, (, 1990-07-11, )]  102 minutes  ...   \n",
       "\n",
       "  Number of employees Divisions Subsidiaries Predecessor Founders Area served  \\\n",
       "0                 NaN       NaN          NaN         NaN      NaN         NaN   \n",
       "\n",
       "  Products Services Revenue Operating income  \n",
       "0      NaN      NaN     NaN              NaN  \n",
       "\n",
       "[1 rows x 154 columns]"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_Step5_df.head(1) # Check latest DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7099"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Write a try-except block to catch errors while extracting the IMDb ID using a regular expression string and\n",
    "#  dropping any imdb_id duplicates. If there is an error, capture and print the exception.\n",
    "\n",
    "form_imdb=\"(tt\\d{7})\"\n",
    "\n",
    "# For personal use - extract IMDB identifier from 'imdb_link' and store in 'imdb_id' column \n",
    "movies_Step5_df['imdb_id'] = movies_Step5_df['imdb_link'].str.extract(form_imdb)\n",
    "movies_Step6_df=movies_Step5_df[movies_Step5_df['imdb_id'].notna()]\n",
    "\n",
    "# for movies_Step5_df['imdb_id'] in movies_Step5_df['imdb_link']:\n",
    "#     try:\n",
    "#         movies_Step5_df['imdb_id'] = movies_Step5_df['imdb_link'].str.extract(form_imdb)\n",
    "#         movies_Step5_df.drop_duplicates(subset='imdb_id', inplace=True)\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         pass\n",
    "\n",
    "len(movies_Step6_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['url', 'year', 'imdb_link', 'title', 'Based on', 'Starring',\n",
       "       'Cinematography', 'Release date', 'Running time', 'Country', 'Language',\n",
       "       'Budget', 'Box office', 'Director', 'Distributor', 'Editor(s)',\n",
       "       'Composer(s)', 'Producer(s)', 'Production company(s)', 'Writer(s)',\n",
       "       'imdb_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  7. Write a list comprehension to keep the columns that don't have null values from the wiki_movies_df DataFrame.\n",
    "wiki_columns_to_keep = [column for column in movies_Step6_df.columns if movies_Step6_df[column].isnull().sum() < len(movies_Step6_df) * 0.9]\n",
    "movies_Step7_df = movies_Step6_df[wiki_columns_to_keep]\n",
    "movies_Step7_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5517"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8. Create a variable (i.e. list???) that will hold the non-null values from the “Box office” column.\n",
    "box_office=movies_Step7_df['Box office'].dropna() # Creates list of non-null contents from DataFrame\n",
    "len(box_office)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Convert the box office data created in Step 8 to string values using the lambda and join functions.\n",
    "box_office = box_office.apply(lambda x: ' '.join(x) if type(x) == list else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Write a regular expression to match the six elements of \"form_one\" of the box office data.\n",
    "form_one = r'\\$\\d+\\.?\\d*\\s*[mb]illion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Write a regular expression to match the three elements of \"form_two\" of the box office data.\n",
    "form_two = r'\\$\\d{1,3}(?:,\\d{3})+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Add the parse_dollars function.\n",
    "def parse_dollars(s):\n",
    "    # if s is not a string, return NaN\n",
    "    if type(s) != str:\n",
    "        return np.nan\n",
    "\n",
    "    # if input is of the form $###.# million\n",
    "    if re.match(r'\\$\\s*\\d+\\.?\\d*\\s*milli?on', s, flags=re.IGNORECASE):\n",
    "\n",
    "        # remove dollar sign and \" million\"\n",
    "        s = re.sub('\\$|\\s|[a-zA-Z]','', s)\n",
    "\n",
    "        # convert to float and multiply by a million\n",
    "        value = float(s) * 10**6\n",
    "\n",
    "        # return value\n",
    "        return value\n",
    "\n",
    "    # if input is of the form $###.# billion\n",
    "    elif re.match(r'\\$\\s*\\d+\\.?\\d*\\s*billi?on', s, flags=re.IGNORECASE):\n",
    "\n",
    "        # remove dollar sign and \" billion\"\n",
    "        s = re.sub('\\$|\\s|[a-zA-Z]','', s)\n",
    "\n",
    "        # convert to float and multiply by a billion\n",
    "        value = float(s) * 10**9\n",
    "\n",
    "        # return value\n",
    "        return value\n",
    "\n",
    "    # if input is of the form $###,###,###\n",
    "    elif re.match(r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+(?!\\s[mb]illion)', s, flags=re.IGNORECASE):\n",
    "\n",
    "        # remove dollar sign and commas\n",
    "        s = re.sub('\\$|,','', s)\n",
    "\n",
    "        # convert to float\n",
    "        value = float(s)\n",
    "\n",
    "        # return value\n",
    "        return value\n",
    "\n",
    "    # otherwise, return NaN\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bob Thomson\\anaconda3\\envs\\PythonData\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Bob Thomson\\anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "489564729284.0"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 13. Clean the box office column in the wiki_movies_df DataFrame.\n",
    "# Use 'box_office' list to create new column in DataFrame\n",
    "movies_Step7_df['box_office'] = box_office.str.extract(f'({form_one}|{form_two})', flags=re.IGNORECASE)[0].apply(parse_dollars)\n",
    "# movies_Step7_df.columns\n",
    "movies_Step7_df.drop('Box office', axis=1, inplace=True)\n",
    "movies_Step13_df=movies_Step7_df\n",
    "movies_Step13_df['box_office'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bob Thomson\\anaconda3\\envs\\PythonData\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "177607020531.0"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 14. Clean the budget column in the wiki_movies_df DataFrame.\n",
    "budget = movies_Step13_df['Budget'].dropna() # Creates list of non-null contents from DataFrame\n",
    "budget = budget.apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "budget = budget.str.replace(r'\\$.*[-—–](?![a-z])', '$', regex=True)\n",
    "matches_form_one = budget.str.contains(form_one, flags=re.IGNORECASE)\n",
    "matches_form_two = budget.str.contains(form_two, flags=re.IGNORECASE)\n",
    "budget[~matches_form_one & ~matches_form_two]\n",
    "budget = budget.str.replace(r'\\[\\d+\\]\\s*', '')\n",
    "budget[~matches_form_one & ~matches_form_two]\n",
    "movies_Step13_df['budget'] = budget.str.extract(f'({form_one}|{form_two})', flags=re.IGNORECASE)[0].apply(parse_dollars)\n",
    "movies_Step13_df.drop('Budget', axis=1, inplace=True)\n",
    "movies_Step14_df=movies_Step13_df\n",
    "movies_Step14_df['budget'].sum() # Check on total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bob Thomson\\anaconda3\\envs\\PythonData\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['url', 'year', 'imdb_link', 'title', 'Based on', 'Starring',\n",
       "       'Cinematography', 'Running time', 'Country', 'Language', 'Director',\n",
       "       'Distributor', 'Editor(s)', 'Composer(s)', 'Producer(s)',\n",
       "       'Production company(s)', 'Writer(s)', 'imdb_id', 'box_office', 'budget',\n",
       "       'release_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 15. Clean the release date column in the wiki_movies_df DataFrame.\n",
    "release_date = movies_Step14_df['Release date'].dropna().apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "date_form_one = r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s[123]\\d,\\s\\d{4}'\n",
    "date_form_two = r'\\d{4}.[01]\\d.[123]\\d'\n",
    "date_form_three = r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s\\d{4}'\n",
    "date_form_four = r'\\d{4}'\n",
    "\n",
    "movies_Step14_df['release_date'] = pd.to_datetime(release_date.str.extract(f'({date_form_one}|{date_form_two}|{date_form_three}|{date_form_four})')[0], infer_datetime_format=True)\n",
    "movies_Step14_df.drop('Release date', axis=1, inplace=True)\n",
    "movies_Step15_df=movies_Step14_df\n",
    "movies_Step15_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bob Thomson\\anaconda3\\envs\\PythonData\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# 16. Clean the running time column in the wiki_movies_df DataFrame.\n",
    "running_time = movies_Step15_df['Running time'].dropna().apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "\n",
    "running_time_extract = running_time.str.extract(r'(\\d+)\\s*ho?u?r?s?\\s*(\\d*)|(\\d+)\\s*m')\n",
    "\n",
    "running_time_extract = running_time_extract.apply(lambda col: pd.to_numeric(col, errors='coerce')).fillna(0)\n",
    "\n",
    "movies_Step15_df['running_time'] = running_time_extract.apply(lambda row: row[0]*60 + row[1] if row[2] == 0 else row[2], axis=1)\n",
    "movies_Step15_df.drop('Running time', axis=1, inplace=True)\n",
    "movies_Step16_df=movies_Step15_df\n",
    "\n",
    "wiki_movies_df=movies_Step16_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     \n",
    "    # 2. Clean the Kaggle metadata.\n",
    "file_dir = \"C:/Users/Bob Thomson/ETL Module/\"\n",
    "kaggle_metadata = pd.read_csv(f'{file_dir}movies_metadata.csv', low_memory=False)\n",
    "ratings = pd.read_csv(f'{file_dir}ratings.csv')\n",
    "\n",
    "# Keep only rows that have False for 'adult', then delete entire 'adult' column\n",
    "kaggle_metadata = kaggle_metadata[kaggle_metadata['adult'] == 'False'].drop('adult',axis='columns')\n",
    "\n",
    "kaggle_metadata['video'] = kaggle_metadata['video'] == 'True'\n",
    "\n",
    "kaggle_metadata['budget'] = kaggle_metadata['budget'].astype(int)\n",
    "kaggle_metadata['id'] = pd.to_numeric(kaggle_metadata['id'], errors='raise')\n",
    "kaggle_metadata['popularity'] = pd.to_numeric(kaggle_metadata['popularity'], errors='raise')\n",
    "kaggle_metadata['release_date'] = pd.to_datetime(kaggle_metadata['release_date'])\n",
    "\n",
    "\n",
    "\n",
    "ratings['timestamp'] = pd.to_datetime(ratings['timestamp'], unit='s')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Merged the two DataFrames into the movies DataFrame.\n",
    "movies_df = pd.merge(wiki_movies_df, kaggle_metadata, on='imdb_id', suffixes=['_wiki','_kaggle']\n",
    "\n",
    "                     \n",
    "# 4. Drop unnecessary columns from the merged DataFrame.\n",
    "# Create list where Wiki title does not match Kaggle title\n",
    "movies_df[movies_df['title_wiki'] != movies_df['title_kaggle']][['title_wiki','title_kaggle']]\n",
    "                     \n",
    "# 5. Add in the function to fill in the missing Kaggle data.\n",
    "# Show any rows where title_kaggle is empty\n",
    "movies_df[(movies_df['title_kaggle'] == '') | (movies_df['title_kaggle'].isnull())]\n",
    "                     \n",
    "movies_df.fillna(0).plot(x=movies_df['Running time'], y=movies_df['runtime'], kind='scatter')\n",
    "                     \n",
    "movies_df[(movies_df['release_date_wiki'] > '1996-01-01') & (movies_df['release_date_kaggle'] < '1965-01-01')].index\n",
    "\n",
    "movies_df = movies_df.drop(movies_df[(movies_df['release_date_wiki'] > '1996-01-01') & (movies_df['release_date_kaggle'] < '1965-01-01')].index)\n",
    "                     \n",
    "movies_df[movies_df['release_date_wiki'].isnull()]\n",
    "                     \n",
    "movies_df['Language'].apply(lambda x: tuple(x) if type(x) == list else x).value_counts(dropna=False)\n",
    "                     \n",
    "movies_df[['Production company(s)','production_companies']]\n",
    "                     \n",
    "movies_df.drop(columns=['title_wiki','release_date_wiki','Language','Production company(s)'], inplace=True)\n",
    "                     \n",
    "fill_missing_kaggle_data(movies_df, 'runtime', 'running_time')\n",
    "fill_missing_kaggle_data(movies_df, 'budget_kaggle', 'budget_wiki')\n",
    "fill_missing_kaggle_data(movies_df, 'revenue', 'box_office')\n",
    "movies_df\n",
    "                     \n",
    "for col in movies_df.columns:\n",
    "    lists_to_tuples = lambda x: tuple(x) if type(x) == list else x\n",
    "    value_counts = movies_df[col].apply(lists_to_tuples).value_counts(dropna=False)\n",
    "    num_values = len(value_counts)\n",
    "    if num_values == 1:\n",
    "        print(col)\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df['video'].value_counts(dropna=False)\n",
    "                     \n",
    "# 7. Filter the movies DataFrame for specific columns.\n",
    "movies_df = movies_df.loc[:, ['imdb_id','id','title_kaggle','original_title','tagline','belongs_to_collection','url','imdb_link',\n",
    "                       'runtime','budget_kaggle','revenue','release_date_kaggle','popularity','vote_average','vote_count',\n",
    "                       'genres','original_language','overview','spoken_languages','Country',\n",
    "                       'production_companies','production_countries','Distributor',\n",
    "                       'Producer(s)','Director','Starring','Cinematography','Editor(s)','Writer(s)','Composer(s)','Based on'\n",
    "                      ]]\n",
    "# 8. Rename the columns in the movies DataFrame.                   \n",
    "movies_df.rename({'id':'kaggle_id',\n",
    "                  'title_kaggle':'title',\n",
    "                  'url':'wikipedia_url',\n",
    "                  'budget_kaggle':'budget',\n",
    "                  'release_date_kaggle':'release_date',\n",
    "                  'Country':'country',\n",
    "                  'Distributor':'distributor',\n",
    "                  'Producer(s)':'producers',\n",
    "                  'Director':'director',\n",
    "                  'Starring':'starring',\n",
    "                  'Cinematography':'cinematography',\n",
    "                  'Editor(s)':'editors',\n",
    "                  'Writer(s)':'writers',\n",
    "                  'Composer(s)':'composers',\n",
    "                  'Based on':'based_on'\n",
    "                 }, axis='columns', inplace=True)\n",
    "                     \n",
    "    \n",
    "# 9. Transform and merge the ratings DataFrame.                    \n",
    "rating_counts = ratings.groupby(['movieId','rating'], as_index=False).count() \\\n",
    "                .rename({'userId':'count'}, axis=1) \\\n",
    "                .pivot(index='movieId',columns='rating', values='count')\n",
    "                     \n",
    "rating_counts.columns = ['rating_' + str(col) for col in rating_counts.columns]\n",
    "                     \n",
    "movies_with_ratings_df[rating_counts.columns] = movies_with_ratings_df[rating_counts.columns].fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
